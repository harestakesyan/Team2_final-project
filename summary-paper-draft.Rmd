---
title: "Heartbreakers: Estimating the Risk Factors of Cardiovascular Disease"
author: "By: Hovhannes Arestakesyan, Karina Martinez, Timberley Thompson, Chenxu Wang, & Zhe Yu"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
<<<<<<< Updated upstream
#RMD Settings
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 

#Packages
library(ezids)
library(tidyverse)
library(tinytex)
require(rmarkdown)

#Data
cardio_orig = data.frame(read.csv("cardio_train.csv", header = TRUE, sep=';'))
str(cardio_orig)

cardio = cardio_orig[-c(1)] #get rid of id
cardio$age = cardio$age/365 # transfer days to years
cardio$bmi = cardio$weight/((cardio$height/100)**2) #add bmi variable

cardio_clean = outlierKD2(cardio, bmi, TRUE, TRUE, TRUE, TRUE) 
cardio_clean = outlierKD2(cardio_clean, ap_hi, TRUE, TRUE, TRUE, TRUE) 
cardio_clean = outlierKD2(cardio_clean, ap_lo, TRUE, TRUE, TRUE, TRUE)
cardio_clean = na.omit(cardio_clean) #remove NA rows

cardio_clean_final = cardio_clean
cardio_clean_final$gender = as.factor(cardio_clean$gender)
cardio_clean_final$cholesterol = as.factor(cardio_clean$cholesterol) 
cardio_clean_final$gluc = as.factor(cardio_clean$gluc)
cardio_clean_final$smoke = as.factor(cardio_clean$smoke)
cardio_clean_final$alco = as.factor(cardio_clean$alco)
cardio_clean_final$active = as.factor(cardio_clean$active)
cardio_clean_final$cardio = as.factor(cardio_clean$cardio)
=======
#library(ezids)
#library(tidyverse)
#library(tinytex)
#require(rmarkdown)
#knitr::opts_chunk$set(warning = F, results = "hide", message = F)
#options(scientific=T, digits = 3) 

>>>>>>> Stashed changes
```
# I. Background

Cardiovascular disease is the leading cause of death globally, killing an estimated 17.9 million people each year (World Health Organization). Cardiovascular disease refers to any of a group of conditions affecting one's heart and blood vessels; these conditions can include heart failure, arrhythmia, aortic disease and more (Cleveland Clinic).

<<<<<<< HEAD:summary paper draft.Rmd
<<<<<<< Updated upstream
The World Health Organization asserts that an "unhealthy diet, physical inactivity, tobacco use" and alcohol abuse are the most important behavioral risk factors in developing heart disease. Engaging in such activities can often lead to "raised blood pressure, raised blood glucose... and obesity" (World Health Organization).
=======
The World Health Organization asserts that "unhealthy diet, physical inactivity, tobacco use" and alcohol abuse are the most important behavioral risk factors in developing heart disease. Engaging in such activities can often lead to "raised blood pressure, raised blood glucose... and obesity" (World Health Organization).
>>>>>>> Stashed changes
=======
The World Health Organization asserts that an unhealthy diet, physical inactivity, tobacco use and alcohol abuse are the most important behavioral risk factors in developing heart disease. Engaging in such activities can often lead to raised blood pressure, raised blood glucose... and obesity (World Health Organization).
>>>>>>> main:summary-paper-draft.Rmd

This research paper is an investigation of The World Health Organization's statements. The research team analyzed data on cardiovascular disease to determine the risk factors of the disease and recommend a model to predict cardiovascular disease in patients.

## SMART Questions
Specifically, the research team answers the following Specific, Measurable, Achievable, Relevant, and Time-oriented (SMART) questions:  

  1. How accurately can the model predict the probability that a patient has cardiovascular disease?
  2. What are the top three factors associated with cardiovascular disease? Does this corroborate the risk factors observed by the World Health Organization?  
  3. Is there any association between an individual's sex and whether they have 
cardiovascular disease? Are men more prone to cardiovascular diseases as compared to
women?


## Dataset Description

<<<<<<< HEAD:summary paper draft.Rmd
<<<<<<< Updated upstream
Data analysis was performed on the Cardiovascular Disease dataset from [Kaggle.com](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset). After some data cleaning, the final dataset, `cardio_clean_final`, has `r nrow(cardio_clean_final)` observations and the following variables:
=======
Data analysis was performed on the Cardiovascular Disease dataset from [Kaggle.com](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset). After some data cleaning, the final dataset, `Cardio`, had roughly 63,000 observations and the following variables:
>>>>>>> Stashed changes
=======
Data analysis was performed on the Cardiovascular Disease dataset from [Kaggle.com](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset).  We cleaned the data according to the following pre-processing steps: generated a `bmi` variable from `height` and `weight`, removed outliers for `bmi`, `ap_hi` and `ap_lo`, and converted variables to factors where appropriate. The final dataset, `cardio_clean_final`, has `r nrow(cardio_clean_final)` observations and the following `r ncol(cardio_clean_final)` variables:
>>>>>>> main:summary-paper-draft.Rmd

### Variables

Variable | Type | Definition  
  :-     |  :-- |  :----
`age`	 | Number | Age in years
`gender` |Factor w/ 2 levels | Gender (1: women, 2: men)
`height` | Number | Height in centimeters (cm)
`weight` |Number | Weight in kilograms (kg)
`bmi` | Number | Body Max Index (kg/m^2^)
`ap_hi` | Integer | Systolic blood pressure
`ap_lo` | Integer | Diastolic blood pressure
`cholesterol` |Factor w/ 3 levels| Cholesterol (1: normal, 2: above normal, 3: well above normal)
`gluc` |Factor w/ 3 levels| Glucose (1: normal, 2: above normal, 3: well above normal)
`smoke` |Factor w/ 2 levels| Whether patient smokes or not (0: no, 1: yes)
`alco` |Factor w/ 2 levels| Whether patient consumes alcohol or not (0: no, 1: yes)
`active` |Factor w/ 2 levels| Whether patient is physically active or not (0: no, 1: yes)
`cardio` |Factor w/ 2 levels| Presence or absence of cardiovascular disease (0: absent, 1: present)

<<<<<<< Updated upstream
# II. Exploratory Data Analysis
## Categorical Variables

```{r cat.graphs, results='markup'}
require(patchwork)
disease <- subset(cardio_clean_final, cardio==1)
healthy <- subset(cardio_clean_final, cardio==0)

#cholesterol
cholesterol.1 <- ggplot(cardio_clean_final, aes(x=cardio, fill= cholesterol)) +
  geom_bar(position="fill") +
  scale_x_discrete(labels=c("1" = "Has CVD", "0" = "No CVD")) +
  scale_y_continuous(labels = scales::percent) +
  labs( title = "Cholesterol", y = "", x = "",
        fill = "Cholesterol Level") +
  scale_fill_manual(values=c("#f4cccc", "#e06666", "#990000"), 
                    labels = c("Normal", "Above Normal", "Well Above Normal")) +
  theme_minimal()

#Glucose
gluc.1 <- ggplot(cardio_clean_final, aes(x=cardio, fill= gluc)) +
  geom_bar(position="fill") +
  scale_x_discrete(labels=c("1" = "Has CVD", "0" = "No CVD")) +
  scale_y_continuous(labels = scales::percent) +
  labs( title = "Glucose", y = "", x = "",
        fill = "Glucose Level") +
  scale_fill_manual(values=c("#f4cccc", "#e06666", "#990000"), 
                    labels = c("Normal", "Above Normal", "Well Above Normal")) +
  theme_minimal()

#Gender
cardio_clean_final$gender.yn<- as.factor(ifelse(cardio_clean_final$gender== "1", "Women", "Men"))

gender.1 <- ggplot(cardio_clean_final, aes(x=cardio, fill= gender.yn)) +
  geom_bar(position="fill") +
  scale_x_discrete(labels=c("1" = "Has CVD", "0" = "No CVD")) +
  scale_y_continuous(labels = scales::percent) +
  labs( title = "Gender",
        y = "", x = "", fill = "") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()

#Smoke
cardio_clean_final$smoke.yn<- as.factor(ifelse(cardio_clean_final$smoke== "1", "Yes", "No"))

smoke.1 <- ggplot(cardio_clean_final, aes(x=cardio, fill= smoke.yn)) +
  geom_bar(position="fill") +
  scale_x_discrete(labels=c("1" = "Has CVD", "0" = "No CVD")) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Tobacco Use", y = "", x = "", fill = "Smoker") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()

#alcohol
  cardio_clean_final$alco.yn<- as.factor(ifelse(cardio_clean_final$alco== "1", "Yes", "No"))

alco.1 <- ggplot(cardio_clean_final, aes(x=cardio, fill= alco.yn)) +
  geom_bar(position="fill") +
  scale_x_discrete(labels=c("1" = "Has CVD", "0" = "No CVD")) +
  scale_y_continuous(labels = scales::percent) +
  labs( title = "Alcohol Use", y = "", x = "", fill = "Drinks Alcohol") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()

#active
cardio_clean_final$active.yn<- as.factor(ifelse(cardio_clean_final$active== "1", "Yes", "No"))

active.1 <- ggplot(cardio_clean_final, aes(x=cardio, fill= active.yn)) +
  geom_bar(position="fill") +
  scale_x_discrete(labels=c("1" = "Has CVD", "0" = "No CVD")) +
  scale_y_continuous(labels = scales::percent) +
  labs( title = "Physical Activity", y = "", x = "", fill = "Physically Active") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal() 

gender.1 + cholesterol.1 + gluc.1 + smoke.1 +  alco.1 + active.1 + plot_layout(ncol = 2)
```

By exploring the data, we found that the most noticeable differences between people with and without cardiovascular disease (CVD) were in cholesterol and glucose. `r sprintf("%.1f", (sum(disease$cholesterol!= "1")/nrow(disease)) * 100)`% of people with cardiovascular disease have above normal cholesterol levels, while only `r sprintf("%.1f", (sum(healthy$cholesterol!= "1")/nrow(disease)) * 100)`% of people *without* the disease have above normal cholesterol. Similarly, `r sprintf("%.1f", (sum(disease$gluc!="1")/nrow(disease)) * 100)`% of people with the disease have above normal glucose, while only `r sprintf("%.1f", (sum(healthy$gluc!="1")/nrow(disease)) * 100)`% of people *without* the disease have above normal glucose.

The differences between the two groups (people with and without cardiovascular disease) are less noticeable when examining gender and lifestyle factors. The percentage of women in the "has CVD" group is nearly equal to the percentage of women in the "no CVD" group. Likewise, the percentage of alcohol drinkers is nearly the same in the "has CVD" group and the "no CVD" group.

Unsurprisingly, there is a slightly higher percentage of physically active people in the "no CVD" group than in the "has CVD" group. However, it *is* surprising that there is a slightly higher percentage of smokers in the "*no CVD*" group" than in the "CVD" group. We found that xx% of people without CVD were smokers, while only xx% of people with CVD were smokers. This finding seems to contradict experts' assertions that tobacco use can cause cardiovascular disease (FDA).



## Chi-Squared Test
We performed chi-squared tests to further explore the data and determine the statistical significance of the differences we observed between the two groups.

Categorical Variable | Chi-Square | P-Value | df  
  :-     |  :- |  :-| :-
  `gender`  | 0.4 | 0.5 | 1
  `cholesterol` | 2991 | <2e-16 | 2
  `glucose` | 478 | <2e-16 | 2
  `smoke` | 21 | 4e-06 | 1
  `alco` | 7 | 0.006 | 1
  `active` | 81 | <2e-16 | 1
```{r chi}
disease <- subset(cardio_clean_final, cardio==1)
healthy <- subset(cardio_clean_final, cardio==0)

#Gender
cardio_vs_gender = table(cardio_clean_final$cardio, cardio_clean_final$gender)
chi_gender = chisq.test(cardio_vs_gender)

#Cholesterol
cardio_vs_cholesterol=table(cardio_clean_final$cardio, cardio_clean_final$cholesterol)
chi_cholesterol = chisq.test(cardio_vs_cholesterol)

#Glucose
cardio_vs_glucose = table(cardio_clean_final$cardio, cardio_clean_final$gluc)
chi_glucose = chisq.test(cardio_vs_glucose)

#Smoking
cardio_vs_smoke = table(cardio_clean_final$cardio, cardio_clean_final$smoke)
chi_smoke = chisq.test(cardio_vs_smoke)

#Alcohol
cardio_vs_alco = table(cardio_clean_final$cardio, cardio_clean_final$alco)
chi_alco = chisq.test(cardio_vs_alco)

#Physical Activity
cardio_vs_active = table(cardio_clean_final$cardio, cardio_clean_final$active)
chi_active = chisq.test(cardio_vs_active)


```

In plain English, describe what the results of the chi-squared test reveal. What conclusions can be drawn from the results? Do they corroborate the conclusions drawn from the graphs?

## Continuous Variables

```{r cont.graphs}
disease <- subset(cardio_clean_final, cardio==1)
healthy <- subset(cardio_clean_final, cardio==0)

#age
cardio_clean_final$cardio.yn<- as.factor(ifelse(cardio_clean_final$active== "1", "Yes", "No"))

age.kde <- ggplot(cardio_clean_final, aes(x = age, fill= cardio.yn)) + 
  geom_density(position = "stack") +
  geom_vline(aes(xintercept=mean(disease$age)), color="pink3", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=mean(healthy$age)), color="steelblue", linetype="dashed", size=1) +
  scale_x_continuous(limits = c(30,70)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Age",
       subtitle = "Age Distribution (Stacked)",
       fill = "Has CVD", x = "Age", y = " ") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()


#height
height.kde <- ggplot(cardio_clean_final, aes(x = height, fill= cardio.yn)) + 
  geom_density(position = "stack") +
  geom_vline(aes(xintercept=mean(disease$height)), color="pink3", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=mean(healthy$height)), color="steelblue", linetype="dashed", size=1) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Height",
       subtitle = "Height Distribution (Stacked)",
       fill = "Has CVD", x = "Height (cm)", y = " ") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()



#weight
weight.kde <- ggplot(cardio_clean_final, aes(x = weight, fill= cardio.yn)) + 
  geom_density(position = "stack") +
  geom_vline(aes(xintercept=mean(disease$weight)), color="pink3", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=mean(healthy$weight)), color="steelblue", linetype="dashed", size=1) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Weight",
       subtitle = "Weight Distribution (Stacked)",
       fill = "Has CVD", x = "Weight (kg)", y = " ") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()



#bmi
bmi.kde <- ggplot(cardio_clean_final, aes(x = bmi, fill= cardio.yn)) + 
  geom_density(position = "stack") +
  geom_vline(aes(xintercept=mean(disease$bmi)), color="pink3", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=mean(healthy$bmi)), color="steelblue", linetype="dashed", size=1) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "BMI",
       subtitle = "BMI Distribution (Stacked)",
       fill = "Has CVD", x = "BMI", y = " ") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()



#systolic bp
ap_hi.kde <- ggplot(cardio_clean_final, aes(x = ap_hi, fill= cardio.yn)) + 
  geom_density(position = "stack") +
  geom_vline(aes(xintercept=mean(disease$ap_hi)), color="pink3", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=mean(healthy$ap_hi)), color="steelblue", linetype="dashed", size=1) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(breaks = c(seq(90,170,20))) +
  labs(title = "Systolic BP",
       subtitle = "Systolic BP Distribution (Stacked)",
       fill = "Has CVD", x = "Systolic BP", y = " ") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()



#diastolic bp
ap_lo.kde <- ggplot(cardio_clean_final, aes(x = ap_lo, fill= cardio.yn)) + 
  geom_density(position = "stack") +
  geom_vline(aes(xintercept=mean(disease$ap_lo)), color="pink3", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=mean(healthy$ap_lo)), color="steelblue", linetype="dashed", size=1) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(breaks = c(seq(65,105,10))) +
  labs(title = "Diastolic BP",
       subtitle = "Diastolic BP Distribution (Stacked)",
       fill = "Has CVD", x = "Diastolic BP", y = " ") +
  scale_fill_manual(values=c("#0000da", "#990000")) +
  theme_minimal()



require(ggpubr)
ggarrange(age.kde, height.kde, weight.kde, bmi.kde, ap_hi.kde, ap_lo.kde, ncol=2, nrow=3, common.legend = TRUE, legend = "bottom", heights=c(2,2,2))


```

According to the graphs, how do CVD patients differ from non-CVD  patients with respect to the continuous variables? Please note that the pink dashed lines indicate the means for CVD patients while the blue dashed lines indicate the means for healthy patients.

## Welch Two-Sample T-Test
What is the purpose of the  t-test? 

Continuous Variable | CVD Avg. | No CVD Avg. | t | p-value
:- | :- | :- | :- | :-
`age` | 55 | 51.8 | 61 | <2e-16
`height` | 165 | 165 | -4 | 1e-04
`weight`| 75.3 | 71.3 | 41 | <2e-16
`bmi` | 27.8 | 26.3 | 46 | <2e-16
`ap_hi` | 133 | 120 | 120 | <2e-16
`ap_lo` | 84.3 | 79.1 | 89 | <2e-16

```{r ttest}

cardio_pos = subset(cardio_clean_final, cardio_clean_final$cardio == 1)
cardio_neg = subset(cardio_clean_final, cardio_clean_final$cardio == 0)

#age
ttest_age = t.test(cardio_pos$age, cardio_neg$age)
ttest_age

#height
ttest_height = t.test(cardio_pos$height, cardio_neg$height)
ttest_height

#weight
ttest_weight = t.test(cardio_pos$weight, cardio_neg$weight)
ttest_weight

#bmi
ttest_bmi = t.test(cardio_pos$bmi, cardio_neg$bmi)
ttest_bmi

#ap.hi
ttest_ap_hi = t.test(cardio_pos$ap_hi, cardio_neg$ap_hi)
ttest_ap_hi

#ap.lo
ttest_ap_lo = t.test(cardio_pos$ap_lo, cardio_neg$ap_lo)
ttest_ap_lo

```
In plain English, describe what the results of the t-test reveal. What conclusions can be drawn from the results? 


## Correlations
What is the purpose of examining correlations?

```{r corrplot}
loadPkg("corrplot")


# corrplot with spearman method for categorical variables
cardio.cor.1 <- cor(cardio_clean, method="spearman")
corrplot(cardio.cor.1, order = "hclust", type="lower", addCoef.col="darkred", number.cex=0.6, tl.cex=1,title="Correlation Matrix", mar=c(0,0,1,0))
```

What does the corrplot tell us?

** further exploration of correlations * *

<<<<<<< HEAD:summary paper draft.Rmd
# III. Model Comparison
=======
# III. Statistical Models
## Feature Selection

## Logistic Model
How did the EDA influence your choices when developing this model? (For example: Why is a logistic model appropriate for this data? What variables did you use and why?) What is the purpose of the model?
>>>>>>> main:summary-paper-draft.Rmd

## Feature selection  
In the EDA, t-tests and Chi-square tests were used to compare whether the response variables `age`, `gender`, `height`, `weight`, `ap_hi`, `ap_lo`, `cholesterol`, `gluc`, `smoke`, `alco`, `active` and `bmi` have effects on the predictor variable `cardio`, and the p-values of the tests were shown in the table below:  
```{r results='markup'}
tab <- matrix(c( '<2e-16','0.6', '8e-07', '<2e-16', '<2e-16', '<2e-16', '<2e-16', '<2e-16', '1e-06', '0.006', '<2e-16', '<2e-16'), ncol=12, byrow = TRUE)
rownames(tab) <- "p_value"
colnames(tab) <- c("Age_year", "Gender", "Height","Weight","Systolic(ap_hi)", "Diastolic(ap_low)", "Cholesterol","Glucose","smoke", "Alcohol", "Physical_activity","BMI")
tab <- as.table(tab)
xkabledply(tab, "p-value Comparison")  
```

**From the above table, we found that all the response variables have relationship with the predictor variable `cardio` except the `gender` variable. Next we further confirmed this using the `bestglm` function.  

<<<<<<< HEAD:summary paper draft.Rmd
```{r bestglm, results='markup'}
loadPkg("bestglm")
loadPkg("leaps")
loadPkg("ggplot2")
cardio_clean_final_glm <- cardio_clean_final
colnames(cardio_clean_final_glm)[12] <- "y"
cardio_clean_final_glm <- cardio_clean_final_glm[c("age", "gender", "height", "weight","ap_hi", "ap_lo", "cholesterol", "gluc", "smoke", "alco", "active", "bmi", "y")]
=======
### Logistic Model Evaluation
>>>>>>> main:summary-paper-draft.Rmd

res.bestglm <- bestglm(Xy = cardio_clean_final_glm, family = binomial,
            IC = "AIC", method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm") 
unloadPkg("leaps") 
```  
`gender` and `bmi` were excluded from the model that has lowest criterion value, indicating these two valuables may not have strong effects on `cardio`. But among the 5 models the function generated, the criterion values are very close, and `gender` was voted as `FALSE` three time, while `bmi` was only voted twice. So we are not confidence in removing these two valuables from the following modeling steps. In the KNN modeling, we compare whether these two variables can affect the model performances. Also, since the correlations matrix showed the valuables `age`, `cholesterol`, `bmi`, `ap_hi` and `ap_lo` had relatively high coefference values with `cardio`, we also performed the KNN modeling with these 5 valuables.    

## K-Nearest Neighbor (KNN)     
### Convert factors into numeric, and Scale/center the data       
```{r results='markup'}
cardio_num <- cardio_clean_final_glm
colnames(cardio_num)[13] <- "cardioi"
cardio_num[1:12] <- sapply(cardio_num[1:12],as.numeric)
cardio_scale <- cardio_num
cardio_scale[1:12] <- as.data.frame(scale(cardio_num[1:12], center = TRUE, scale = TRUE))
str(cardio_scale)
```  
Dataframe structure after pre-modeling treatment was shown in the above table. All the response variables were converted in to numeric, and were scaled and centered. They are ready for KNN modeling.  

### KNN modeling using variables with all 13 variables (Model 1)  
#### Train / Test split:  
The dataframe was split into training subset (70% of the total dataframe) and test subset (30% of the total dataframe).  
```{r}
set.seed(42)
cardio_sample <- sample(2, nrow(cardio_scale), replace=TRUE, prob=c(0.7, 0.3))
cardio_training_x <- cardio_scale[cardio_sample==1, 1:12]
cardio_test_x <- cardio_scale[cardio_sample==2, 1:12]
cardio_training_y <- cardio_scale[cardio_sample==1, 13]
cardio_test_y <- cardio_scale[cardio_sample==2, 13]
```

#### Looking for the best K value:  
Odd numbers from 3 to 40 were test one by one to get the best K value. The accuracy values from the model that used these K values were shown in the table and the line graph. According the results, K = 19 is the best K value for Model 1.  

```{r}
loadPkg("FNN")
loadPkg("gmodels")
loadPkg("caret")
K_test <- seq(3, 40, by = 2)
ResultDf = data.frame()
for (k_v in K_test) {
  cardio_pred <- knn(train = cardio_training_x, test = cardio_test_x, cl=cardio_training_y, k=k_v)
  
  cm = confusionMatrix(cardio_pred, reference = cardio_test_y )
  
  cmaccu = cm$overall['Accuracy']

  cmt = data.frame(k=k_v, Total.Accuracy = cmaccu, row.names = NULL ) 
  
  ResultDf = rbind(ResultDf, cmt)
}
```
```{r results='markup'}
xkabledply(ResultDf, "Total Accuracy Summary for KNN Model 1")
```

```{r}
library(ggplot2)
ggplot(ResultDf, aes(x=k, y=Total.Accuracy)) +
  geom_line(color = "skyblue", size = 1.5) +
  geom_point(size = 3, color = "blue") + 
  labs(title = "Total.Accuracy vs K (Model 1)")
```  
#### Modeling results with the best K value (Model 1, K = 19)  

Detailed results and the confusion matrix using K=19 were shown below.  

```{r results='markup'}
   cardio_pred_19 <- knn(train = cardio_training_x, test = cardio_test_x, cl=cardio_training_y, k=19)
  KNN_Mode_1 = confusionMatrix(cardio_pred_19, reference = cardio_test_y)
  xkabledply(as.matrix(KNN_Mode_1), title = paste("Confusion Matrix for KNN Model 1") ) 
  xkabledply(data.frame(KNN_Mode_1$overall['Accuracy']), title=paste("Total Accuracy of KNN Model 1"))
  xkabledply(data.frame(KNN_Mode_1$byClass), title=paste("Metrics of KNN Model 1"))
```  
 The overall performance is acceptable, but we still want to see whether remove `gender` and `bmi` can improve the modeling.  

<<<<<<< HEAD:summary paper draft.Rmd
### KNN modeling using variables without `gender` and `bmi` (Model 2)  
#### Train / Test split:  
The dataframe was split into training subset (70% of the total dataframe) and test subset (30% of the total dataframe). The valuables `gender` and `bmi` were excluded from the train/test split.
```{r}
cardio_scale2 <- cardio_scale[c(1, 3:11, 13)]
cardio_scale2
set.seed(42)
cardio_sample2 <- sample(2, nrow(cardio_scale2), replace=TRUE, prob=c(0.7, 0.3))
cardio_training_x2 <- cardio_scale2[cardio_sample2==1, 1:10]
cardio_test_x2 <- cardio_scale2[cardio_sample2==2, 1:10]
cardio_training_y2 <- cardio_scale2[cardio_sample2==1, 11]
cardio_test_y2 <- cardio_scale2[cardio_sample2==2, 11]
```

#### Looking for the best K value:  
Odd numbers from 3 to 40 were used for the test. The accuracy values from the model that used these K values were shown in the table and the line graph. According the results, K = 29 is the best K value for the KNN modeling without `gender` and `bmi`.

```{r}
K_test <- seq(3, 40, by = 2)
ResultDf2 = data.frame()
for (k_v in K_test) {
  cardio_pred2 <- knn(train = cardio_training_x2, test = cardio_test_x2, cl=cardio_training_y2, k=k_v)
  
  cm2 = confusionMatrix(cardio_pred2, reference = cardio_test_y2 )
  
  cmaccu2 = cm2$overall['Accuracy']

  cmt2 = data.frame(k=k_v, Total.Accuracy = cmaccu2, row.names = NULL ) 
  
  ResultDf2 = rbind(ResultDf2, cmt2)
}
```
```{r results='markup'}
xkabledply(ResultDf2, "Total Accuracy Summary for KNN Model 2")
```

```{r}
library(ggplot2)
ggplot(ResultDf2, aes(x=k, y=Total.Accuracy)) +
  geom_line(color = "skyblue", size = 1.5) +
  geom_point(size = 3, color = "blue") + 
  labs(title = "Total.Accuracy vs K (Model 2)")
```  

#### Modeling results with the best K value (Model 2, K = 29)  

Detailed results and the confusion matrix of model 2 using k = 29 were shown below. Removing `gender` and `bmi` slightly improved the performance. 

```{r results='markup'}
  cardio_pred_29 <- knn(train = cardio_training_x2, test = cardio_test_x2, cl=cardio_training_y2, k=29)
  KNN_Mode_2 = confusionMatrix(cardio_pred_29, reference = cardio_test_y2)
  xkabledply(as.matrix(KNN_Mode_2), title = paste("Confusion Matrix for KNN Model 2") ) 
  xkabledply(data.frame(KNN_Mode_2$overall['Accuracy']), title=paste("Total Accuracy of KNN Model 2"))
  xkabledply(data.frame(KNN_Mode_2$byClass), title=paste("Metrics of KNN Model 2"))
```  

Next we want to check whether only use the 5 valuables that provided by correlation matrix will be a better model.  

### KNN modeling using only `age`, `cholesterol`, `bmi`, `ap_hi` and `ap_lo` (Model 3)  
#### Train / Test split:  
The dataframe was split into training subset (70% of the total dataframe) and test subset (30% of the total dataframe). Only `age`, `cholesterol`, `bmi`, `ap_hi` and `ap_lo` were used for the modeling. 
```{r}
cardio_scale3 <- cardio_scale[c(1, 5:7, 12:13)]
cardio_scale3
set.seed(42)
cardio_sample3 <- sample(2, nrow(cardio_scale3), replace=TRUE, prob=c(0.7, 0.3))
cardio_training_x3 <- cardio_scale3[cardio_sample3==1, 1:5]
cardio_test_x3 <- cardio_scale3[cardio_sample3==2, 1:5]
cardio_training_y3 <- cardio_scale3[cardio_sample3==1, 6]
cardio_test_y3 <- cardio_scale3[cardio_sample3==2, 6]
```

#### Looking for the best K value:  
Odd numbers from 3 to 40 were used for the test. The accuracy values from the model that used these K values were shown in the table and the line graph. According the results, K = 31 is the best K value for the KNN modeling.

```{r}
K_test <- seq(3, 40, by = 2)
ResultDf3 = data.frame()
for (k_v in K_test) {
  cardio_pred3 <- knn(train = cardio_training_x3, test = cardio_test_x3, cl=cardio_training_y3, k=k_v)
  
  cm3 = confusionMatrix(cardio_pred3, reference = cardio_test_y3 )
  
  cmaccu3 = cm3$overall['Accuracy']

  cmt3 = data.frame(k=k_v, Total.Accuracy = cmaccu3, row.names = NULL ) 
  
  ResultDf3 = rbind(ResultDf3, cmt3)
}
```
```{r results='markup'}
xkabledply(ResultDf3, "Total Accuracy Summary")
```

```{r}
library(ggplot2)
ggplot(ResultDf3, aes(x=k, y=Total.Accuracy)) +
  geom_line(color = "skyblue", size = 1.5) +
  geom_point(size = 3, color = "blue") + 
  labs(title = "Total.Accuracy vs K")
```  

#### Modeling results with the best K value (Model 3, K = 31)  

The confusion matrix of model 3 using k = 31 were shown below. 

```{r results='markup'}
  cardio_pred_31 <- knn(train = cardio_training_x3, test = cardio_test_x3, cl=cardio_training_y3, k=31)
  KNN_Mode_3 = confusionMatrix(cardio_pred_31, reference = cardio_test_y3 )
  xkabledply(as.matrix(KNN_Mode_3), title = paste("Confusion Matrix for KNN Model 3") )
```  

```{r results='markup'}
 xkabledply(data.frame(KNN_Mode_1$overall['Accuracy'], KNN_Mode_2$overall['Accuracy'], KNN_Mode_3$overall['Accuracy']), title=paste("Total Accuracy Comparision of the Three KNN Models"))

 xkabledply(data.frame(KNN_Mode_1$byClass, KNN_Mode_2$byClass, KNN_Mode_3$byClass), title=paste("Metrics Comparision of KNN the Three KNN Models"))
```
**The total accuracy and other metrics of the three models were listed in the above tables. For summary, all three models have an acceptable performance, but not outstanding. More specifically, model 2 has a overall better performance comparing to model 1. But model 2 and model 3 have their own strength and weaknesses. The accuracy and recall value of model 2 are higher than model 3, while the precision value is higher in model 3. Recall value is more related to false negative rate and the precision value is used to represent to the false positive rate. It's hard to say which model is the best one, but we should choose the proper model according to our aims. If minimizing false positives is our focus, model 3 might be a good option, and model 2 is more suitable is we want to minimize  false negative rate.**  
**One of the limitation of the KNN modeling is this model has difficulties in identifying feature importance. So from here we can't answer the question that which are the top 3 factors that affect the onset of cardiovascular diseases. Our following modeling using logistic regression and classification tree will answer the question.**  

=======
### KNN Model Evaluation
...

**Conclusion:** Is this a good model? Why or why not? What are its strengths and weaknesses?
>>>>>>> main:summary-paper-draft.Rmd

## Classification Tree


This model is Classification Tree model. We could use the classification tree model to predict the absence and presence of disease visually. It is very convenient. And we will discuss the performance of this model below.

First step, cleaning the dataset for preparing to build the model. Ensure the variavles are all numerical variables. And delete the ID, which has no relationship to the results.

```{r , results='markup'}



#read in original data set
cardio_tree_orig = data.frame(read.csv("cardio_train.csv", header = TRUE, sep=';'))

#remove id column, convert age to years, add bmi col
cardio_tree_new = cardio_tree_orig[-c(1)]
cardio_tree_new$age = cardio_tree_new$age/365
cardio_tree_new$bmi = cardio_tree_new$weight/(cardio_tree_new$height/100)**2

#remove outliers from bmi, api_hi and api_lo
cardio_clean_1 = outlierKD2(cardio_tree_new, bmi, TRUE, FALSE, FALSE, FALSE) 
cardio_clean_2 = outlierKD2(cardio_clean_1, ap_hi, TRUE, FALSE, FALSE, FALSE) 
cardio_clean_3 = outlierKD2(cardio_clean_2, ap_lo, TRUE, FALSE, FALSE, FALSE)

#remove NA rows
cardio_clean_3 = na.omit(cardio_clean_3)
cardio_clean_tree_final <- transform(cardio_clean_3, cardio=as.factor(cardio))
cardio_tree = cardio_clean_tree_final[,c(1,2,3,4,13,5,6,7,8,9,10,11,12)]
str(cardio_tree)


```

Then we did the feature selection by random forest. This is a fundamental outcome of the random forest and it shows, for each variable, how important it is in classifying the data.The mean decrease in Gini coefficient is a measure of how each variable contributes to the homogeneity of the nodes and leaves in the resulting random forest. The higher the value of mean decrease Gini score, the higher the importance of the variable in the model. And as we can see from the picture, we chose the top 6 features to build this classification tree model{ap_lo (the opposite of ap_hi) is highly correlated to ap_hi, so it doesnâ€™t gain anything to use it together.}.

```{r Classification Tree feature selection, results=TRUE}
library(randomForest)
fit_im = randomForest(cardio_tree$cardio~., data=cardio_tree)
# Create an importance based on mean decreasing gini
importance(fit_im)
varImpPlot(fit_im)
```



Next, we try to find the best depths in this model. We tried different depths and summary the results
```{r Classification Tree depths result}
loadPkg("rpart")
loadPkg("caret")



# create an empty dataframe to store the results from confusion matrices
confusionMatrixResultDf = data.frame( Depth=numeric(0), Accuracy= numeric(0), Sensitivity=numeric(0), Specificity=numeric(0), Pos.Pred.Value=numeric(0), Neg.Pred.Value=numeric(0), Precision=numeric(0), Recall=numeric(0), F1=numeric(0), Prevalence=numeric(0), Detection.Rate=numeric(0), Detection.Prevalence=numeric(0), Balanced.Accuracy=numeric(0), row.names = NULL )

for (deep in 2:8) {
  kfit <- rpart(cardio ~age+ap_lo+bmi+weight+height+cholesterol, data= cardio_tree, method="class", control = list(maxdepth = deep) )
  # 
  cm = confusionMatrix( predict(kfit, type = "class"), reference = cardio_tree[, "cardio"] ) # from caret library
  # 
  cmaccu = cm$overall['Accuracy']
  # print( paste("Total Accuracy = ", cmaccu ) )
  # 
  cmt = data.frame(Depth=deep, Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
  confusionMatrixResultDf = rbind(confusionMatrixResultDf, cmt)
  # print("Other metrics : ")
}

unloadPkg("caret")
```

As we can see from the results,from the depths 4, the accuracy of different depths is almost same. Therefore, we choosed the depths 6 to build the tree model.
```{r , results="asis", results=TRUE}
xkabledply(confusionMatrixResultDf, title="Cardio Classification Trees summary with varying MaxDepth")
```



Then we built this classification tree model and plot it.
```{r , echo = T, fig.dim=c(6,4), results=TRUE}
set.seed(1)
cardio_tree_fit <- rpart(cardio ~ age+ap_lo+bmi+weight+height+cholesterol , data= cardio_tree, method="class", control = list(maxdepth = 6) )

printcp(cardio_tree_fit) # display the results 
plotcp(cardio_tree_fit) # visualize cross-validation results 
summary(cardio_tree_fit) # detailed summary of splits

# plot tree 
plot(cardio_tree_fit, uniform=TRUE, main="Classification Tree for Cardio")
text(cardio_tree_fit, use.n=TRUE, all=TRUE, cex=.8)

```




```{r  }
# create attractive postcript plot of tree 
post(cardio_tree_fit, file = "cardiotreeTree2.ps", title = "Classification Tree for Cardio")
```





### Results and confusion matrix
And these are the summary results of this model and its confusion matrix.
```{r , include=T, results=TRUE}
loadPkg("caret") 
cm = confusionMatrix( predict(cardio_tree_fit, type = "class") , reference = cardio_tree[, "cardio"])
print('Overall: ')
cm$overall
print('Class: ')
cm$byClass
unloadPkg("caret")
```

We can see the accuracy of classification tree is 0.695, precision is 0.673, recall is 0.773 and F1 scores is 0.72.


```{r Classification Tree, results="asis"}
xkabledply(cm$table, "confusion matrix")
```

24579 rows of data with outcome as 0 are correctly predicted by model(True Negative)
19019 rows of data with outcome as 1 are correctly predicted by model(True Positive)
11943 rows of data which has actual outcome of 0 are predicted wrongly as 1 by the model(False Positive)
7207 rows of data which has actual outcome of 1 are predicted wrongly as 0 by the model(False Negative)


### Tree plot
We also tried two other ways to plot the tree, with library `rpart.plot` and a "fancy" plot using the library `rattle` to make the tree plot more beautifully. 
```{r Classification Tree fancyplot, results=TRUE}
loadPkg("rpart.plot")
rpart.plot(cardio_tree_fit)
loadPkg("rattle") 
fancyRpartPlot(cardio_tree_fit)
```

Take a look at a plot of the tree, we can find that the leaf nodes predict the label (level of factor variable) .The tree selected contains 3 variables with 5 splits and displayed 6 terminal leaf nodes. 


### ROC curve
Finally, we also checked the ROC and AUC of this classification tree model.   
```{R ROC curve of Classification Tree, results=TRUE}
library(rpart)
rp <- rpart(cardio ~ age+ap_lo+bmi+weight+height+cholesterol, data = cardio_tree)
library(ROCR)
pred <- prediction(predict(cardio_tree_fit, type = "prob")[, 2], cardio_tree$cardio)
tree.predict.prob <- predict(cardio_tree_fit, type = "prob")[, 2]
plot(performance(pred, "tpr", "fpr"), main = "ROC Cardio")
auc = performance(pred, 'auc')
slot(auc, 'y.values')
abline(0, 1, lty = 2)

```

The area-under-curve is 0.727 which is close to 0.8. Hence,this model is a good model.


**Conclusion:** 
According to the mean decrease in Gini, the top 3 risk factors are age, ap_hi and bmi.
Although the accuracy of this model is 69.5%, the area-under-curve is 0.727 which is close to 0.8. 
Hence, this model is kind of a good model. 


## Model Comparison

-- insert model comparison chart --

Compare the strengths, weaknesses, and findings of each model.

# IV. Conclusion
**1. How accurately can the model predict the probability that a patient has cardiovascular disease?**  
Provide an answer. Use the results of our analysis to support the answer.
  
**2. What are the top three factors associated with cardiovascular disease? Does this corroborate the risk factors observed by the World Health Organization?**  
Provide an answer. Use the results of our analysis to support the answer.

**3. Is there an association between and individual's sex and whether they have cardiovascular disease?**  
Provide an answer. Use the results of our analysis to support the answer.

**4. What recommendations can be made to reduce cardiovascular risk and prevent heart attacks and strokes?**  
Provide an answer. Use the results of our analysis to support the answer.

Discuss the limitations of the dataset and our analysis. Discuss what can be done to improve research in this area.
=======
# III. Exploratory Data Analysis
## Categorical Variables
How do CVD patients differ from non-CVD  patients with respect to the categorical variables?

## Chi-Squared Test
What do the chi-squared tests tell us?

## Continuous Variables
How do CVD patients differ from non-CVD  patients with respect to the continuous variables?

## Statistical Tests
What do the hypothesis tests tell us?


## All Variables
Summarize what we've learned from the EDA. How did this inform our choice in models?

# IV. Model Comparison
## Logistic Model
...

### Model Evaluation

** ROC & AUC **
** McFadden Value **

### Limitations
...

## KNN
...

## Classification Tree

## Discussion

# V. Conclusion
## Predictions

## Risk Factors

## Reccommendations

>>>>>>> Stashed changes

# References

<<<<<<< Updated upstream
Cleveland Clinic medical professional (Ed.). (2021, October 5). *Cardiovascular disease: Heart disease causes and symptoms.* Cleveland Clinic. Retrieved August 2, 2022, from https://my.clevelandclinic.org/health/diseases/21493-cardiovascular-disease#:~:text=Cardiovascular%20disease%20is%20the%20leading,women%20die%20from%20cardiovascular%20disease. 
=======
Cleveland Clinic medical professional (Ed.). (2021, October 5). Cardiovascular disease: Heart disease causes and symptoms. Cleveland Clinic. Retrieved August 2, 2022, from https://my.clevelandclinic.org/health/diseases/21493-cardiovascular-disease#:~:text=Cardiovascular%20disease%20is%20the%20leading,women%20die%20from%20cardiovascular%20disease. 
>>>>>>> Stashed changes

FDA Center for Tobacco Products. (2021, November 9). *How smoking affects heart health*. U.S. Food and Drug Administration. Retrieved August 5, 2022, from https://www.fda.gov/tobacco-products/health-effects-tobacco-use/how-smoking-affects-heart-health#References 

World Health Organization. (n.d.). *Cardiovascular diseases*. World Health Organization. Retrieved August 2, 2022, from https://www.who.int/health-topics/cardiovascular-diseases#tab=tab_1 





