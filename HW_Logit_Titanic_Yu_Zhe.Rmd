---
title: "Intro to DS - Logit Regression"
author: "Zhe Yu"
# date: "today"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# HW Assignment - Logit Regression

We have the historic Titanic dataset to study here. You can use `Titanic` on api.regression.fit
for the dataset, or if given, from local file `Titanic.csv`.  
The variables in the dataset are:  

* `survival`: Survival,	0 = No, 1 = Yes
* `pclass`: Ticket class, 1 = 1st, 2 = 2nd, 3 = 3rd
* `sex`: Gender / Sex
* `age`: Age in years
* `sibsp`: # of siblings / spouses on the Titanic
* `parch`: # of parents / children on the Titanic
* `ticket`: Ticket number (for superstitious ones)
* `fare`: Passenger fare
* `embarked`: Port of Embarkment	C: Cherbourg, Q: Queenstown, S: Southampton

The questions listed here are the basic guidelines, not the only goal, in this homework. For example, after you load the dataframe, even though the question does not ask you to look at the structure of the dataframe, you most likely should. You are given less and less “specific to-dos” in the homework, as you are getting more familiar with the data analytic process. Calculate and figure out the necessary info needed in the analysis, even though the questions might not ask for them explicitly. When you look at your own work, you should find it convincing, answering the questions and technically sound.  


## Titanic Tragedy Dataset  

### Question 1

**Import the dataset into R**  
```{r results='markup'}
titanic_orig = api_rfit("Titanic")
xkabledplyhead(titanic_orig)
str(titanic_orig)
```
**Answer**: The dataframe `Titanic` was improted and saved as `titanic_orig`. It's head and structure were explored.  


### Question 2 
**Age**  
```{r}
sum(is.na(titanic_orig$age))
sum(titanic_orig$age==0) 
titanic_clean1 <- subset(titanic_orig, age!=0)
```
**Answer**: There are `r sum(titanic_orig$age==0)` missing values in `Age`. Those observations were removed and the rest of the dataset was saved to a new file `titanic_clean1`.  

### Question 3  
**More clean up**  
```{r}
titanic_clean <- titanic_clean1
titanic_clean$survived = factor(titanic_clean1$survived)
titanic_clean$pclass = factor(titanic_clean1$pclass)
titanic_clean$sibsp = factor(titanic_clean1$sibsp)
titanic_clean$parch = factor(titanic_clean1$parch)
```
**Answer**: The valuables `survived`, `class`, `sibsp` and `parch` were converted into factor valuables.

## Pre-logistic Regression

### Question 4  
**Survival and age**  
```{r}
titanic_sur <- subset(titanic_clean, survived==1)
titanic_nons <- subset(titanic_clean, survived==0)
t_age <- t.test(titanic_sur$age, titanic_nons$age)
t_age
```
**Answer**: We can use t-test to check whether `age` affects `survival`. The dataframe was split into two group according to whether the passengers were survived or not. The p value of the test is `r format(t_age$p.value)`, which is less than 0.05, so `age` can affect `survival`.

### Question 5  
**Survival and gender**  
```{r}
survival_vs_sex = table(titanic_clean$survived, titanic_clean$sex)
Chi_sex <- chisq.test(survival_vs_sex)
Chi_sex
```
**Answer**: We can use Chi-square test to check whether `sex` affects `survival`. The p value of the test is `r format(Chi_sex$p.value)`, which is less than 0.05, so `sex` can affect `survival`.

### Question 6   
**Survival and pclass**  
```{r}
survival_vs_pclass = table(titanic_clean$survived, titanic_clean$pclass)
Chi_pclass <- chisq.test(survival_vs_pclass)
Chi_pclass
```
**Answer**: We can use Chi-square test to check whether `pclass` affects `survival`. The p value of the test is `r format(Chi_pclass$p.value)`, which is less than 0.05, so `pclass` can affect `survival`.

## Logistic Regression

### Question 7   
**Survival and age + pclass**  
```{r}

survival_Logit <- glm(survived ~ age + pclass, data = titanic_clean, family = "binomial")
survival_Logit
```

```{r results = 'markup'}
xkabledply(survival_Logit, title = paste("Logistic Regression :", format(formula(survival_Logit)) ))
expcoeff = exp(coef(survival_Logit))
xkabledply( as.table(expcoeff), title = "Exponential of coefficients in Logit Reg" , wide=T)
```

```{r confusionMatrix, results='markup'}
loadPkg("regclass")
xkabledply( confusion_matrix(survival_Logit), title = "Confusion matrix from Logit Model" )
```
```{r roc_auc}
loadPkg("pROC")
prob=predict(survival_Logit, type = "response" )
titanic_clean$prob=prob
h <- roc(survived~prob, data=titanic_clean)
auc(h) 
plot(h)
```
```{r McFadden}
loadPkg("pscl") 
survival_Logitpr2 = pR2(survival_Logit)
survival_Logitpr2
```


**Answer**:  
The logit model with `age` + `pclass` as predictors was built using the `glm` function to predict the `survived`. Confusion matrix, roc_auc and McFadden were used for model evaluation.  
  
According to the coefficients, `age` has negative effects on `survival`, for every unit gain in age, the log(odd-ratio) of survival decreases by 0.0418. The `pclass` valuable also has negative effects on `survival`. Use pclass 1 as baseline, log(odd-ratio) decrease by 1.1375 when changing from 1 to 2, and decrease by 2.4695 when changing from 1 to 3.  
  
The growth and decay factors were calculated by exponentiate the coefficients. According to the results, every unit increase in `age`, `pchass2` or `pclass3`(with other variables unchanged) will decrease the odds-ratio of survive by a factor of 0.0418, 1.1375 or 2.4695, respectively.  
  
According to the confusion matrix, the accuracy of the model is (344 + 152) / 714 =0.695, the precision of the model is 152/232=0.655, the recall rate is 152/290=0.524, and the specificity is 344/424=0.811.  
  
The area-under-curve is `r auc(h)`, which is less than 0.8, indicating the model is not considered a good fit.  
  
With the McFadden value of `r survival_Logitpr2['McFadden']`, which is analogous to the coefficient of determination $R^2$, only about 14% of the variations in y is explained by the explanatory variables in the model.  
  
For summary, the accuracy of the model is not very good, AUC is less than 0.8, and the McFadden value is also low, so it is not a very good model.  


### Question 8  
**More features**  
```{r results='markup'}
survival_Logit2 <- glm(survived ~ age + pclass + sex, data = titanic_clean, family = "binomial")
xkabledply(survival_Logit2, title = paste("Logistic Regression :", format(formula(survival_Logit2)) ))
```

```{r confusionMatrix2, results='markup'}
loadPkg("regclass")
xkabledply( confusion_matrix(survival_Logit2), title = "Confusion matrix from the new Logit Model" )
```

```{r roc_auc2}
loadPkg("pROC")
prob2=predict(survival_Logit2, type = "response" )
titanic_clean$prob2=prob2
h2 <- roc(survived~prob2, data=titanic_clean)
auc(h2) 
plot(h2)
```

```{r McFadden2}
loadPkg("pscl") 
survival_Logitpr2_2 = pR2(survival_Logit2)
survival_Logitpr2_2
```
**Answer**:  
The logit model with `age` + `pclass` + `sex` as predictors was built using the `glm` function to predict the `survived`. Confusion matrix, roc_auc and McFadden were used for model evaluation.  
  
According to the coefficients, `age`, `pclass` and `sex` all have negative effects on `survival`.  
  
According to the confusion matrix, the accuracy of the model is (356 + 207) / 714 =0.789, the precision of the model is 207/275=0.753, the recall rate is 207/290=0.714, and the specificity is 344/424=0.84.  
  
We have here the area-under-curve of `r auc(h2)`, which is higher than 0.8, indicating the model is considered a good fit.  
  
The McFadden value of this model is `r survival_Logitpr2_2['McFadden']`, which is also increased compared to the previous model.  
  
For summary, the accuracy, roc_auc and McFadden are all increased after adding `sex` to the model. Now it is a better model compares to the previous one.  

### Question 9  
**Sample Predictions**  
```{r results='asis'}
newdata1 <- data.frame(age = 10, pclass = as.factor(2), sex = "female")
predict(survival_Logit2, newdata = newdata1, type = "response") -> pred_response 
print(paste(" Chance of survival for a female, age 10, second class passenger is: ",pred_response))

newdata2 <- data.frame(age = 20, pclass = as.factor(1), sex = "male")
predict(survival_Logit2, newdata = newdata2, type = "response") -> pred_response2 
print(paste(" Chance of survival for a male, age 20, first class passenger is: ",pred_response2))
```  
  
**Answer**: `predict` function was used to predict the survival probability on new data based on the second model. 

### Question 10  
**Summary**  

**Answer**: By comparing the two modeling method: ``r format(formula(survival_Logit))`` and ``r format(formula(survival_Logit2))``, we can find that both `age` and `pclass` can negatively affect the survival rate, and adding `sex` to the model can increase the modeling performance. Increasing `age` or `sex` is male have lower probability to survival, indicating in the face of death, more chances were given to young people and females, which is very impressive. But on the other hand, negative effects of `pclass` on the survival rate means people in the lower ticket class (less rich) is more easily to die, which is a sad fact.
