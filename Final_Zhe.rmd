# Team 2 Final Project - Categorical variables EDA - Zhe  
**Look at the structure of the dataframe `cardio_clean_final`.**
```{r}
str(cardio_clean_final)
```  



**Chi-square test was used to test whether the categorical variables and presence of cardiovascular disease are independent.**  

**1. Whether `cardio` and `gender` are independent.**  
- H0: cardio and gender are independent.  
- H1: they are not independent.  
```{r results='markup'}
cardio_vs_gender = table(cardio_clean_final$cardio, cardio_clean_final$gender)
chi_gender = chisq.test(cardio_vs_gender)
chi_gender
```  
The p-value from the Chi-square test is 0.2, which is larger than 0.05. So we failed to reject the null hypothesis. This result indicating `gender` difference won't affect the onset of  cardiovascular diseases.  

**2. Whether `cardio` and `cholesterol` are independent.**  
- H0: cardio and cholesterol are independent.  
- H1: they are not independent.  
```{r results='markup'}
cardio_vs_cholesterol = table(cardio_clean_final$cardio, cardio_clean_final$cholesterol)
chi_cholesterol = chisq.test(cardio_vs_cholesterol)
chi_cholesterol
```  
The p-value from the Chi-square test is less than 2e-16, which is smaller than 0.05. So we can reject the null hypothesis. This result indicating `cholesterol` level will contribute to the onset of cardiovascular diseases.  

**3. Whether `cardio` and `gluc` are independent.**  
- H0: cardio and gluc are independent.  
- H1: they are not independent.  
```{r results='markup'}
cardio_vs_glucose = table(cardio_clean_final$cardio, cardio_clean_final$gluc)
chi_glucose = chisq.test(cardio_vs_glucose)
chi_glucose
```  
The p-value from the Chi-square test is less than 2e-16, which is smaller than 0.05. So we can reject the null hypothesis. This result indicating glucose (`gluc`) level will contribute to the onset of cardiovascular diseases.  

**4. Whether `cardio` and `smoke` are independent.**  
- H0: cardio and smoke are independent.  
- H1: they are not independent.  
```{r results='markup'}
cardio_vs_smoke = table(cardio_clean_final$cardio, cardio_clean_final$smoke)
chi_smoke = chisq.test(cardio_vs_smoke)
chi_smoke
```  
The p-value from the Chi-square test is 3e-08, which is smaller than 0.05. So we can reject the null hypothesis. This result indicating smoke or not will contribute to the onset of cardiovascular diseases.  

**5. Whether `cardio` and `alco` are independent.**  
- H0: cardio and alco are independent.  
- H1: they are not independent.  
```{r results='markup'}
cardio_vs_alco = table(cardio_clean_final$cardio, cardio_clean_final$alco)
chi_alco = chisq.test(cardio_vs_alco)
chi_alco
```  
The p-value from the Chi-square test is 0.002, which is smaller than 0.05. So we can reject the null hypothesis. This result indicating whether the patient consumes alcohol or not will contribute to the onset of cardiovascular diseases.  

**6. Whether `cardio` and `active` are independent.**  
- H0: cardio and active are independent.  
- H1: they are not independent.  
```{r results='markup'}
cardio_vs_active = table(cardio_clean_final$cardio, cardio_clean_final$active)
chi_active = chisq.test(cardio_vs_active)
chi_active
```  
The p-value from the Chi-square test is less then 2e-16, which is smaller than 0.05. So we can reject the null hypothesis. This result indicating whether the patient is physically active or not will contribute to the onset of cardiovascular diseases.  

**Based on the Chi-square tests we performed, we found `gender` is not contribute to the presence or absence of cardiovascular disease, while `cholesterol`, `gluc`, `smoke`, `alco` and `active` are the variables that can affect whether the patient has cardiovascular disease or not.**

# Feature selection
**From the t-tests and Chi-square tests, we found that all the response variables have relationship with the predictor variable `cardio` except the `gender` variable. Next we tested the strength of the relationships with the `bestglm` function.

```{r bestglm, results='markup'}
loadPkg("bestglm")
loadPkg("leaps")
loadPkg("ggplot2")
cardio_clean_final_glm <- cardio_clean_final
colnames(cardio_clean_final_glm)[12] <- "y"
cardio_clean_final_glm <- cardio_clean_final_glm[c("age", "gender", "height", "weight","ap_hi", "ap_lo", "cholesterol", "gluc", "smoke", "alco", "active", "bmi", "y")]

res.bestglm <- bestglm(Xy = cardio_clean_final_glm, family = binomial,
            IC = "AIC", method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm") 
unloadPkg("leaps") 
```
Based on the results, `gender` and `bmi` may not have strong effects on `cardio`. But we still want to compare whether these two variables will affect the KNN modeling. 

# **K-Nearest Neighbor (KNN)**   
## **Convert facrors into numeric, and scale and center the data**   
```{r results='markup'}
cardio_num <- cardio_clean_final_glm
colnames(cardio_num)[13] <- "cardioi"
cardio_num[1:12] <- sapply(cardio_num[1:12],as.numeric)
cardio_scale <- cardio_num
cardio_scale[1:12] <- as.data.frame(scale(cardio_num[1:12], center = TRUE, scale = TRUE))
str(cardio_scale)
```  
## **KNN modeling using variables with all 13 variables.**  
## Train / Test split:  
The dataframe was seperated into training subset (70% of the total dataframe) and test subset (30% of the total dataframe)
```{r}
set.seed(42)
cardio_sample <- sample(2, nrow(cardio_scale), replace=TRUE, prob=c(0.7, 0.3))
cardio_training_x <- cardio_scale[cardio_sample==1, 1:12]
cardio_test_x <- cardio_scale[cardio_sample==2, 1:12]
cardio_training_y <- cardio_scale[cardio_sample==1, 13]
cardio_test_y <- cardio_scale[cardio_sample==2, 13]
```

## Looking for the best K value:  
Odd numbers from 3 to 50 were used for the test. The accuracy values from the model that used these K values were shown in the table and the line graph. According the results, K = 15 is the best K value.

```{r}
loadPkg("FNN")
loadPkg("gmodels")
loadPkg("caret")
K_test <- seq(3, 40, by = 2)
ResultDf = data.frame()
for (k_v in K_test) {
  cardio_pred <- knn(train = cardio_training_x, test = cardio_test_x, cl=cardio_training_y, k=k_v)
  cardio_PRED_Cross <- CrossTable(cardio_test_y, cardio_pred, prop.chisq = FALSE)
  
  cm = confusionMatrix(cardio_pred, reference = cardio_test_y )
  
  cmaccu = cm$overall['Accuracy']

  cmt = data.frame(k=k_v, Total.Accuracy = cmaccu, row.names = NULL ) 
  
  ResultDf = rbind(ResultDf, cmt)
}
```
```{r results='markup'}
xkabledply(ResultDf, "Total Accuracy Summary")
```

```{r}
library(ggplot2)
ggplot(ResultDf, aes(x=k, y=Total.Accuracy)) +
  geom_line(color = "skyblue", size = 1.5) +
  geom_point(size = 3, color = "blue") + 
  labs(title = "Total.Accuracy vs K")
```
Detailed result of K=15
```{r results='markup'}
  cardio_pred_15 <- knn(train = cardio_training_x, test = cardio_test_x, cl=cardio_training_y, k=19)
  cardio_PRED_Cross <- CrossTable(cardio_test_y, cardio_pred, prop.chisq = FALSE)
  cm = confusionMatrix(cardio_pred_15, reference = cardio_test_y)
  cmaccu = cm$overall['Accuracy']
  print( paste("Accuracy_K_19 = ", cmaccu ) )
```
## **KNN modeling using variables without `gender` and `bmi`.**  
## Train / Test split:  
The dataframe was split into training subset (70% of the total dataframe) and test subset (30% of the total dataframe)
```{r}
cardio_scale2 <- cardio_scale[c(1, 3:11, 13)]
cardio_scale2
set.seed(42)
cardio_sample2 <- sample(2, nrow(cardio_scale2), replace=TRUE, prob=c(0.7, 0.3))
cardio_training_x2 <- cardio_scale2[cardio_sample2==1, 1:10]
cardio_test_x2 <- cardio_scale2[cardio_sample2==2, 1:10]
cardio_training_y2 <- cardio_scale2[cardio_sample2==1, 11]
cardio_test_y2 <- cardio_scale2[cardio_sample2==2, 11]
```

## Looking for the best K value:  
Odd numbers from 3 to 50 were used for the test. The accuracy values from the model that used these K values were shown in the table and the line graph. According the results, K = 43 is the best K value.

```{r}
K_test <- seq(3, 40, by = 2)
ResultDf2 = data.frame()
for (k_v in K_test) {
  cardio_pred2 <- knn(train = cardio_training_x2, test = cardio_test_x2, cl=cardio_training_y2, k=k_v)
  cardio_PRED_Cross2 <- CrossTable(cardio_test_y2, cardio_pred2, prop.chisq = FALSE)
  
  cm2 = confusionMatrix(cardio_pred2, reference = cardio_test_y2 )
  
  cmaccu2 = cm2$overall['Accuracy']

  cmt2 = data.frame(k=k_v, Total.Accuracy = cmaccu2, row.names = NULL ) 
  
  ResultDf2 = rbind(ResultDf2, cmt2)
}
```
```{r results='markup'}
xkabledply(ResultDf2, "Total Accuracy Summary")
```

```{r}
library(ggplot2)
ggplot(ResultDf2, aes(x=k, y=Total.Accuracy)) +
  geom_line(color = "skyblue", size = 1.5) +
  geom_point(size = 3, color = "blue") + 
  labs(title = "Total.Accuracy vs K")
```

```{r results='markup'}
  cardio_pred_43 <- knn(train = cardio_training_x2, test = cardio_test_x2, cl=cardio_training_y2, k=29)
  cardio_PRED_Cross <- CrossTable(cardio_test_y2, cardio_pred2, prop.chisq = FALSE)
  cm2 = confusionMatrix(cardio_pred2, reference = cardio_test_y2 )
  cmaccu2 = cm2$overall['Accuracy']
  print( paste("Accuracy_K_29 = ", cmaccu2 ) )
```
                
**After remove `gender` and `bmi`, the accuracy increased from 0.714 to 0.722**, indicating remove these two variables can slightly improve the modeling performance.
